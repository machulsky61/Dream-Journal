{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhd-sJ-CqlpE"
      },
      "source": [
        "#0. Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nxuPRrvZrMrM"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías habituales\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O32QYyzuxsa3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Cómo levantar el df limpio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "directory = 'Data/limp'\n",
        "dataframes = []  # list to hold all dataframes\n",
        "\n",
        "for i in range(1,14):\n",
        "  path = directory + str(i) + '.pickle'\n",
        "  dff = pd.read_pickle(path)\n",
        "  dataframes.append(dff)\n",
        "\n",
        "# Concatenate all dataframes in the list\n",
        "df = pd.concat(dataframes)\n",
        "dfRank = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gHOkoltntvxZ"
      },
      "outputs": [],
      "source": [
        "df[\"raices\"] = df[\"raicesl\"]\n",
        "df[\"text\"] = df[\"dream\"]\n",
        "\n",
        "#Junta y arma un solo \"texto\" con las raíces\n",
        "df['raices_unidas'] = df['raices'].apply(\" \".join)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YH8ySeQx8x6"
      },
      "source": [
        "Es casi igual que antes, solo que con 13 archivos limp#.pickle  \n",
        "También cambiaron las columnas:  \n",
        "['cohesion', 'intent', 'lucidity', 'raicesl', 'rating', 'technique',\n",
        "       'url', 'user', 'dream', 'additional_comments', 'themes', 'settings',\n",
        "       'characters', 'emotions', 'activities']\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGdGHdsyQwu"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "##Cómo levantar el df Viejo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gPrqamGVqnMp"
      },
      "outputs": [],
      "source": [
        "#Correr solo esto para tener un df de 9k entradas\n",
        "#directory = '/content/drive/My Drive/Dreams/data'\n",
        "#df = pd.read_pickle('/content/drive/My Drive/Dreams/data1.pickle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kIXc3X67rGYd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cohesion</th>\n",
              "      <th>intent</th>\n",
              "      <th>lucidity</th>\n",
              "      <th>raicesl</th>\n",
              "      <th>rating</th>\n",
              "      <th>technique</th>\n",
              "      <th>url</th>\n",
              "      <th>user</th>\n",
              "      <th>dream</th>\n",
              "      <th>additional_comments</th>\n",
              "      <th>themes</th>\n",
              "      <th>settings</th>\n",
              "      <th>characters</th>\n",
              "      <th>emotions</th>\n",
              "      <th>activities</th>\n",
              "      <th>raices</th>\n",
              "      <th>text</th>\n",
              "      <th>raices_unidas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[i, be, on, the, ground, floor, of, a, dorm, b...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>haux</td>\n",
              "      <td>i was on the ground floor of a dorm building ...</td>\n",
              "      <td></td>\n",
              "      <td>friendly</td>\n",
              "      <td>town city indoors distorted unfamiliar</td>\n",
              "      <td>friend colleague</td>\n",
              "      <td>emotionless</td>\n",
              "      <td>physical thinking visual location change</td>\n",
              "      <td>[i, be, on, the, ground, floor, of, a, dorm, b...</td>\n",
              "      <td>i was on the ground floor of a dorm building ...</td>\n",
              "      <td>i be on the ground floor of a dorm building th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[i, be, leave, a, job, after, a, shift, have, ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>haux</td>\n",
              "      <td>i was leaving a job after a shift had ended i...</td>\n",
              "      <td></td>\n",
              "      <td>failure friendly</td>\n",
              "      <td>indoors distorted familiar ambiguous</td>\n",
              "      <td>colleague unfamiliar</td>\n",
              "      <td>emotionless</td>\n",
              "      <td>thinking visual movement location change</td>\n",
              "      <td>[i, be, leave, a, job, after, a, shift, have, ...</td>\n",
              "      <td>i was leaving a job after a shift had ended i...</td>\n",
              "      <td>i be leave a job after a shift have end it be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[twilight, my, present, home, i, be, leave, th...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>PearlDiver</td>\n",
              "      <td>twilight my present home i am leaving the hou...</td>\n",
              "      <td>curious dream bl is one of the worst people i ...</td>\n",
              "      <td>music action success failure health friendly</td>\n",
              "      <td>outdoors indoors distorted familiar unfamiliar...</td>\n",
              "      <td>other relative s friend stranger unfamiliar</td>\n",
              "      <td>worry relaxed peaceful</td>\n",
              "      <td>auditory physical thinking visual movement pro...</td>\n",
              "      <td>[twilight, my, present, home, i, be, leave, th...</td>\n",
              "      <td>twilight my present home i am leaving the hou...</td>\n",
              "      <td>twilight my present home i be leave the house ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[when, your, favourite, song, be, announce, in...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>LucidDreamer777</td>\n",
              "      <td>when your favourite song is announced in your...</td>\n",
              "      <td>p s the last song that i played before going t...</td>\n",
              "      <td>music fun</td>\n",
              "      <td>school outdoors</td>\n",
              "      <td>colleague teacher</td>\n",
              "      <td>fear dread happiness shock</td>\n",
              "      <td>auditory thinking visual movement expressive c...</td>\n",
              "      <td>[when, your, favourite, song, be, announce, in...</td>\n",
              "      <td>when your favourite song is announced in your...</td>\n",
              "      <td>when your favourite song be announce in your d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>red</td>\n",
              "      <td>1.25</td>\n",
              "      <td>[serve, customer, be, in, a, mall, style, like...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>LucidDreamer777</td>\n",
              "      <td>serving customers being in a mall styled like...</td>\n",
              "      <td>morning</td>\n",
              "      <td>nightmare</td>\n",
              "      <td>mall outdoors indoors</td>\n",
              "      <td>child other relative s stranger</td>\n",
              "      <td>sadness worry fear dread emotionless</td>\n",
              "      <td>auditory physical thinking visual movement sea...</td>\n",
              "      <td>[serve, customer, be, in, a, mall, style, like...</td>\n",
              "      <td>serving customers being in a mall styled like...</td>\n",
              "      <td>serve customer be in a mall style like an anci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123718</th>\n",
              "      <td>5.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[first, off, ali, do, not, have, the, father, ...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>MtDewWolf</td>\n",
              "      <td>first off ali did not have the father she doe...</td>\n",
              "      <td>omg if this is precognitive i m killing someone</td>\n",
              "      <td></td>\n",
              "      <td>school</td>\n",
              "      <td>other relative s friend</td>\n",
              "      <td>sadness fear dread anxiety</td>\n",
              "      <td></td>\n",
              "      <td>[first, off, ali, do, not, have, the, father, ...</td>\n",
              "      <td>first off ali did not have the father she doe...</td>\n",
              "      <td>first off ali do not have the father she do no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123719</th>\n",
              "      <td>4.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[ali, ben, dan, and, i, be, all, in, the, clas...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>MtDewWolf</td>\n",
              "      <td>ali ben dan and i were all in the classroom a...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>school</td>\n",
              "      <td>friend</td>\n",
              "      <td>confusion</td>\n",
              "      <td>searching</td>\n",
              "      <td>[ali, ben, dan, and, i, be, all, in, the, clas...</td>\n",
              "      <td>ali ben dan and i were all in the classroom a...</td>\n",
              "      <td>ali ben dan and i be all in the classroom acro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123720</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[i, be, in, some, sort, of, a, strange, arena,...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>Elemental_angel</td>\n",
              "      <td>i was in some sort of a strange arena facing ...</td>\n",
              "      <td>do not know where this came from</td>\n",
              "      <td>violence</td>\n",
              "      <td></td>\n",
              "      <td>friend animals</td>\n",
              "      <td>confusion</td>\n",
              "      <td>searching</td>\n",
              "      <td>[i, be, in, some, sort, of, a, strange, arena,...</td>\n",
              "      <td>i was in some sort of a strange arena facing ...</td>\n",
              "      <td>i be in some sort of a strange arena face a bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123721</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[thois, be, suuuch, a, cool, dream, too, bad, ...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>MyBounciness</td>\n",
              "      <td>thois is suuuch a cool dream too bad i dun re...</td>\n",
              "      <td>well elavators symbloize rising up or down on ...</td>\n",
              "      <td>nightmare violence</td>\n",
              "      <td></td>\n",
              "      <td>other relative s</td>\n",
              "      <td>peaceful</td>\n",
              "      <td></td>\n",
              "      <td>[thois, be, suuuch, a, cool, dream, too, bad, ...</td>\n",
              "      <td>thois is suuuch a cool dream too bad i dun re...</td>\n",
              "      <td>thois be suuuch a cool dream too bad i dun rem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123722</th>\n",
              "      <td>4.0</td>\n",
              "      <td>red</td>\n",
              "      <td>2.50</td>\n",
              "      <td>[i, live, on, a, beach, in, a, very, lovely, h...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>toric13</td>\n",
              "      <td>i lived on a beach in a very lovely house exp...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>home</td>\n",
              "      <td>friend</td>\n",
              "      <td>worry peaceful</td>\n",
              "      <td></td>\n",
              "      <td>[i, live, on, a, beach, in, a, very, lovely, h...</td>\n",
              "      <td>i lived on a beach in a very lovely house exp...</td>\n",
              "      <td>i live on a beach in a very lovely house expen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>123723 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        cohesion intent  lucidity  \\\n",
              "0            2.0     -1     -1.00   \n",
              "1            4.0     -1     -1.00   \n",
              "2            3.0     -1     -1.00   \n",
              "3            5.0     -1     -1.00   \n",
              "4            4.0    red      1.25   \n",
              "...          ...    ...       ...   \n",
              "123718       5.0     -1     -1.00   \n",
              "123719       4.0     -1     -1.00   \n",
              "123720       3.0     -1     -1.00   \n",
              "123721       3.0     -1     -1.00   \n",
              "123722       4.0    red      2.50   \n",
              "\n",
              "                                                  raicesl  rating technique  \\\n",
              "0       [i, be, on, the, ground, floor, of, a, dorm, b...     3.0        -1   \n",
              "1       [i, be, leave, a, job, after, a, shift, have, ...     2.0        -1   \n",
              "2       [twilight, my, present, home, i, be, leave, th...     3.0        -1   \n",
              "3       [when, your, favourite, song, be, announce, in...     2.0        -1   \n",
              "4       [serve, customer, be, in, a, mall, style, like...     2.0        -1   \n",
              "...                                                   ...     ...       ...   \n",
              "123718  [first, off, ali, do, not, have, the, father, ...    -1.0        -1   \n",
              "123719  [ali, ben, dan, and, i, be, all, in, the, clas...    -1.0        -1   \n",
              "123720  [i, be, in, some, sort, of, a, strange, arena,...    -1.0        -1   \n",
              "123721  [thois, be, suuuch, a, cool, dream, too, bad, ...    -1.0        -1   \n",
              "123722  [i, live, on, a, beach, in, a, very, lovely, h...    -1.0        -1   \n",
              "\n",
              "                                                      url             user  \\\n",
              "0       http://www.dreamjournal.net/journal/dream/drea...             haux   \n",
              "1       http://www.dreamjournal.net/journal/dream/drea...             haux   \n",
              "2       http://www.dreamjournal.net/journal/dream/drea...       PearlDiver   \n",
              "3       http://www.dreamjournal.net/journal/dream/drea...  LucidDreamer777   \n",
              "4       http://www.dreamjournal.net/journal/dream/drea...  LucidDreamer777   \n",
              "...                                                   ...              ...   \n",
              "123718  http://www.dreamjournal.net/journal/dream/drea...        MtDewWolf   \n",
              "123719  http://www.dreamjournal.net/journal/dream/drea...        MtDewWolf   \n",
              "123720  http://www.dreamjournal.net/journal/dream/drea...  Elemental_angel   \n",
              "123721  http://www.dreamjournal.net/journal/dream/drea...     MyBounciness   \n",
              "123722  http://www.dreamjournal.net/journal/dream/drea...          toric13   \n",
              "\n",
              "                                                    dream  \\\n",
              "0        i was on the ground floor of a dorm building ...   \n",
              "1        i was leaving a job after a shift had ended i...   \n",
              "2        twilight my present home i am leaving the hou...   \n",
              "3        when your favourite song is announced in your...   \n",
              "4        serving customers being in a mall styled like...   \n",
              "...                                                   ...   \n",
              "123718   first off ali did not have the father she doe...   \n",
              "123719   ali ben dan and i were all in the classroom a...   \n",
              "123720   i was in some sort of a strange arena facing ...   \n",
              "123721   thois is suuuch a cool dream too bad i dun re...   \n",
              "123722   i lived on a beach in a very lovely house exp...   \n",
              "\n",
              "                                      additional_comments  \\\n",
              "0                                                           \n",
              "1                                                           \n",
              "2       curious dream bl is one of the worst people i ...   \n",
              "3       p s the last song that i played before going t...   \n",
              "4                                                morning    \n",
              "...                                                   ...   \n",
              "123718   omg if this is precognitive i m killing someone    \n",
              "123719                                                      \n",
              "123720                  do not know where this came from    \n",
              "123721  well elavators symbloize rising up or down on ...   \n",
              "123722                                                      \n",
              "\n",
              "                                               themes  \\\n",
              "0                                           friendly    \n",
              "1                                   failure friendly    \n",
              "2       music action success failure health friendly    \n",
              "3                                          music fun    \n",
              "4                                          nightmare    \n",
              "...                                               ...   \n",
              "123718                                                  \n",
              "123719                                                  \n",
              "123720                                      violence    \n",
              "123721                            nightmare violence    \n",
              "123722                                                  \n",
              "\n",
              "                                                 settings  \\\n",
              "0                 town city indoors distorted unfamiliar    \n",
              "1                   indoors distorted familiar ambiguous    \n",
              "2       outdoors indoors distorted familiar unfamiliar...   \n",
              "3                                        school outdoors    \n",
              "4                                  mall outdoors indoors    \n",
              "...                                                   ...   \n",
              "123718                                            school    \n",
              "123719                                            school    \n",
              "123720                                                      \n",
              "123721                                                      \n",
              "123722                                              home    \n",
              "\n",
              "                                          characters  \\\n",
              "0                                  friend colleague    \n",
              "1                              colleague unfamiliar    \n",
              "2       other relative s friend stranger unfamiliar    \n",
              "3                                 colleague teacher    \n",
              "4                   child other relative s stranger    \n",
              "...                                              ...   \n",
              "123718                      other relative s friend    \n",
              "123719                                       friend    \n",
              "123720                               friend animals    \n",
              "123721                             other relative s    \n",
              "123722                                       friend    \n",
              "\n",
              "                                     emotions  \\\n",
              "0                                emotionless    \n",
              "1                                emotionless    \n",
              "2                     worry relaxed peaceful    \n",
              "3                 fear dread happiness shock    \n",
              "4       sadness worry fear dread emotionless    \n",
              "...                                       ...   \n",
              "123718            sadness fear dread anxiety    \n",
              "123719                             confusion    \n",
              "123720                             confusion    \n",
              "123721                              peaceful    \n",
              "123722                        worry peaceful    \n",
              "\n",
              "                                               activities  \\\n",
              "0               physical thinking visual location change    \n",
              "1               thinking visual movement location change    \n",
              "2       auditory physical thinking visual movement pro...   \n",
              "3       auditory thinking visual movement expressive c...   \n",
              "4       auditory physical thinking visual movement sea...   \n",
              "...                                                   ...   \n",
              "123718                                                      \n",
              "123719                                         searching    \n",
              "123720                                         searching    \n",
              "123721                                                      \n",
              "123722                                                      \n",
              "\n",
              "                                                   raices  \\\n",
              "0       [i, be, on, the, ground, floor, of, a, dorm, b...   \n",
              "1       [i, be, leave, a, job, after, a, shift, have, ...   \n",
              "2       [twilight, my, present, home, i, be, leave, th...   \n",
              "3       [when, your, favourite, song, be, announce, in...   \n",
              "4       [serve, customer, be, in, a, mall, style, like...   \n",
              "...                                                   ...   \n",
              "123718  [first, off, ali, do, not, have, the, father, ...   \n",
              "123719  [ali, ben, dan, and, i, be, all, in, the, clas...   \n",
              "123720  [i, be, in, some, sort, of, a, strange, arena,...   \n",
              "123721  [thois, be, suuuch, a, cool, dream, too, bad, ...   \n",
              "123722  [i, live, on, a, beach, in, a, very, lovely, h...   \n",
              "\n",
              "                                                     text  \\\n",
              "0        i was on the ground floor of a dorm building ...   \n",
              "1        i was leaving a job after a shift had ended i...   \n",
              "2        twilight my present home i am leaving the hou...   \n",
              "3        when your favourite song is announced in your...   \n",
              "4        serving customers being in a mall styled like...   \n",
              "...                                                   ...   \n",
              "123718   first off ali did not have the father she doe...   \n",
              "123719   ali ben dan and i were all in the classroom a...   \n",
              "123720   i was in some sort of a strange arena facing ...   \n",
              "123721   thois is suuuch a cool dream too bad i dun re...   \n",
              "123722   i lived on a beach in a very lovely house exp...   \n",
              "\n",
              "                                            raices_unidas  \n",
              "0       i be on the ground floor of a dorm building th...  \n",
              "1       i be leave a job after a shift have end it be ...  \n",
              "2       twilight my present home i be leave the house ...  \n",
              "3       when your favourite song be announce in your d...  \n",
              "4       serve customer be in a mall style like an anci...  \n",
              "...                                                   ...  \n",
              "123718  first off ali do not have the father she do no...  \n",
              "123719  ali ben dan and i be all in the classroom acro...  \n",
              "123720  i be in some sort of a strange arena face a bl...  \n",
              "123721  thois be suuuch a cool dream too bad i dun rem...  \n",
              "123722  i live on a beach in a very lovely house expen...  \n",
              "\n",
              "[123723 rows x 18 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Todos los pickles (ESTÁ PUESTO HASTA EL 5: TODOS ES HASTA EL 15)\n",
        "#for i in range(2,5):\n",
        "#  path = directory + str(i) + '.pickle'\n",
        "#  df1 = pd.read_pickle(path)\n",
        "#  df = df.append(df1, ignore_index=True)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuxmk0zpt5Lu"
      },
      "source": [
        "#1. Limpieza previa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GfCbjX9z8G2T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['hello', 'welcome', 'to', 'the', 'bieber', 'dream', 'i', 'm', 'no', 'hater', 'or', 'lover', 'so', 'i', 'be', 'in', 'this', 'strange', 'house', 'i', 'don', 't', 'know', 'of', 'and', 'a', 'a', 'concert', 'go', 'on', 'and', 'all', 'these', 'hobo', 'star', 'at', 'me', 'like', 'i', 'm', 'a', 'ball', 'of', 'cheese', 'wait', 'any', 'self', 'concious', 'in', 'this', 'one', 'then', 'he', 'walk', 'out', 'gasp', 'lover', 'faint', 'and', 'hater', 'shoot', 'him', 'in', 'the', 'head', 'jk', 'actually', 'he', 'be', 'quite', 'old', 'and', 'less', 'wimpy', 'look', 'and', 'amazingly', 'he', 'doesn', 't', 'have', 'that', 'kid', 'voice', 'and', 'hair', 'flip', 'thing', 'go', 'on', 'yeah', 'i', 'hate', 'to', 'admit', 'it', 'but', 'he', 'be', 'cute', 'so', 'i', 'felt', 'a', 'if', 'it', 'be', 'real', 'so', 'i', 'take', 'it', 'slow', 'i', 'be', 'just', 'talk', 'or', 'flirt', 'with', 'him', 'and', 'he', 'let', 'me', 'in', 'his', 'limo', 'and', 'jeesh', 'this', 'quite', 'embarassing', 'because', 'i', 'm', 'not', 'even', 'fond', 'of', 'him', 'anyway', 'i', 'be', 'lead', 'in', 'his', 'house', 'and', 'it', 'be', 'actually', 'quite', 'normal', 'no', 'scream', 'little', 'girls', 'no', 'paris', 'or', 'whatever', 'nothing', 'really', 'famous', 'or', 'huge', 'or', 'expensive', 'so', 'i', 'be', 'in', 'his', 'room', 'and', 'i', 'can', 't', 'exactly', 'remember', 'everything', 'but', 'it', 'be', 'quite', 'normal', 'too', 'at', 'that', 'time', 'i', 'actually', 'want', 'to', 'kiss', 'him', 'i', 'get', 'ready', 'about', 'to', 'do', 'it', 'then', 'my', 'dog', 'whine', 'for', 'her', 'to', 'go', 'potty', 'crap']\n",
            "['buzz', 'and', 'jessie', 'from', 'the', 'toy', 'story', 'movie', 'be', 'this', 'close', 'to', 'kiss', 'then', 'i', 'wake', 'up']\n",
            "http://www.dreamjournal.net/journal/dream/dream_id/155289/username/Dragon12\n"
          ]
        }
      ],
      "source": [
        "#Hay algunos repetidos...\n",
        "print(df[\"raices\"][35427])\n",
        "print(df[\"raices\"][35428])\n",
        "print(df[\"url\"][35427])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nnwNfoS0t_H3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cohesion</th>\n",
              "      <th>intent</th>\n",
              "      <th>lucidity</th>\n",
              "      <th>raicesl</th>\n",
              "      <th>rating</th>\n",
              "      <th>technique</th>\n",
              "      <th>url</th>\n",
              "      <th>user</th>\n",
              "      <th>dream</th>\n",
              "      <th>additional_comments</th>\n",
              "      <th>themes</th>\n",
              "      <th>settings</th>\n",
              "      <th>characters</th>\n",
              "      <th>emotions</th>\n",
              "      <th>activities</th>\n",
              "      <th>raices</th>\n",
              "      <th>text</th>\n",
              "      <th>raices_unidas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[i, be, on, the, ground, floor, of, a, dorm, b...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>haux</td>\n",
              "      <td>i was on the ground floor of a dorm building ...</td>\n",
              "      <td></td>\n",
              "      <td>friendly</td>\n",
              "      <td>town city indoors distorted unfamiliar</td>\n",
              "      <td>friend colleague</td>\n",
              "      <td>emotionless</td>\n",
              "      <td>physical thinking visual location change</td>\n",
              "      <td>[i, be, on, the, ground, floor, of, a, dorm, b...</td>\n",
              "      <td>i was on the ground floor of a dorm building ...</td>\n",
              "      <td>i be on the ground floor of a dorm building th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[i, be, leave, a, job, after, a, shift, have, ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>haux</td>\n",
              "      <td>i was leaving a job after a shift had ended i...</td>\n",
              "      <td></td>\n",
              "      <td>failure friendly</td>\n",
              "      <td>indoors distorted familiar ambiguous</td>\n",
              "      <td>colleague unfamiliar</td>\n",
              "      <td>emotionless</td>\n",
              "      <td>thinking visual movement location change</td>\n",
              "      <td>[i, be, leave, a, job, after, a, shift, have, ...</td>\n",
              "      <td>i was leaving a job after a shift had ended i...</td>\n",
              "      <td>i be leave a job after a shift have end it be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[twilight, my, present, home, i, be, leave, th...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>PearlDiver</td>\n",
              "      <td>twilight my present home i am leaving the hou...</td>\n",
              "      <td>curious dream bl is one of the worst people i ...</td>\n",
              "      <td>music action success failure health friendly</td>\n",
              "      <td>outdoors indoors distorted familiar unfamiliar...</td>\n",
              "      <td>other relative s friend stranger unfamiliar</td>\n",
              "      <td>worry relaxed peaceful</td>\n",
              "      <td>auditory physical thinking visual movement pro...</td>\n",
              "      <td>[twilight, my, present, home, i, be, leave, th...</td>\n",
              "      <td>twilight my present home i am leaving the hou...</td>\n",
              "      <td>twilight my present home i be leave the house ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[when, your, favourite, song, be, announce, in...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>LucidDreamer777</td>\n",
              "      <td>when your favourite song is announced in your...</td>\n",
              "      <td>p s the last song that i played before going t...</td>\n",
              "      <td>music fun</td>\n",
              "      <td>school outdoors</td>\n",
              "      <td>colleague teacher</td>\n",
              "      <td>fear dread happiness shock</td>\n",
              "      <td>auditory thinking visual movement expressive c...</td>\n",
              "      <td>[when, your, favourite, song, be, announce, in...</td>\n",
              "      <td>when your favourite song is announced in your...</td>\n",
              "      <td>when your favourite song be announce in your d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>red</td>\n",
              "      <td>1.25</td>\n",
              "      <td>[serve, customer, be, in, a, mall, style, like...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>LucidDreamer777</td>\n",
              "      <td>serving customers being in a mall styled like...</td>\n",
              "      <td>morning</td>\n",
              "      <td>nightmare</td>\n",
              "      <td>mall outdoors indoors</td>\n",
              "      <td>child other relative s stranger</td>\n",
              "      <td>sadness worry fear dread emotionless</td>\n",
              "      <td>auditory physical thinking visual movement sea...</td>\n",
              "      <td>[serve, customer, be, in, a, mall, style, like...</td>\n",
              "      <td>serving customers being in a mall styled like...</td>\n",
              "      <td>serve customer be in a mall style like an anci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123718</th>\n",
              "      <td>5.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[first, off, ali, do, not, have, the, father, ...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>MtDewWolf</td>\n",
              "      <td>first off ali did not have the father she doe...</td>\n",
              "      <td>omg if this is precognitive i m killing someone</td>\n",
              "      <td></td>\n",
              "      <td>school</td>\n",
              "      <td>other relative s friend</td>\n",
              "      <td>sadness fear dread anxiety</td>\n",
              "      <td></td>\n",
              "      <td>[first, off, ali, do, not, have, the, father, ...</td>\n",
              "      <td>first off ali did not have the father she doe...</td>\n",
              "      <td>first off ali do not have the father she do no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123719</th>\n",
              "      <td>4.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[ali, ben, dan, and, i, be, all, in, the, clas...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>MtDewWolf</td>\n",
              "      <td>ali ben dan and i were all in the classroom a...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>school</td>\n",
              "      <td>friend</td>\n",
              "      <td>confusion</td>\n",
              "      <td>searching</td>\n",
              "      <td>[ali, ben, dan, and, i, be, all, in, the, clas...</td>\n",
              "      <td>ali ben dan and i were all in the classroom a...</td>\n",
              "      <td>ali ben dan and i be all in the classroom acro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123720</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[i, be, in, some, sort, of, a, strange, arena,...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>Elemental_angel</td>\n",
              "      <td>i was in some sort of a strange arena facing ...</td>\n",
              "      <td>do not know where this came from</td>\n",
              "      <td>violence</td>\n",
              "      <td></td>\n",
              "      <td>friend animals</td>\n",
              "      <td>confusion</td>\n",
              "      <td>searching</td>\n",
              "      <td>[i, be, in, some, sort, of, a, strange, arena,...</td>\n",
              "      <td>i was in some sort of a strange arena facing ...</td>\n",
              "      <td>i be in some sort of a strange arena face a bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123721</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>[thois, be, suuuch, a, cool, dream, too, bad, ...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>MyBounciness</td>\n",
              "      <td>thois is suuuch a cool dream too bad i dun re...</td>\n",
              "      <td>well elavators symbloize rising up or down on ...</td>\n",
              "      <td>nightmare violence</td>\n",
              "      <td></td>\n",
              "      <td>other relative s</td>\n",
              "      <td>peaceful</td>\n",
              "      <td></td>\n",
              "      <td>[thois, be, suuuch, a, cool, dream, too, bad, ...</td>\n",
              "      <td>thois is suuuch a cool dream too bad i dun re...</td>\n",
              "      <td>thois be suuuch a cool dream too bad i dun rem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123722</th>\n",
              "      <td>4.0</td>\n",
              "      <td>red</td>\n",
              "      <td>2.50</td>\n",
              "      <td>[i, live, on, a, beach, in, a, very, lovely, h...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>http://www.dreamjournal.net/journal/dream/drea...</td>\n",
              "      <td>toric13</td>\n",
              "      <td>i lived on a beach in a very lovely house exp...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>home</td>\n",
              "      <td>friend</td>\n",
              "      <td>worry peaceful</td>\n",
              "      <td></td>\n",
              "      <td>[i, live, on, a, beach, in, a, very, lovely, h...</td>\n",
              "      <td>i lived on a beach in a very lovely house exp...</td>\n",
              "      <td>i live on a beach in a very lovely house expen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>123723 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        cohesion intent  lucidity  \\\n",
              "0            2.0     -1     -1.00   \n",
              "1            4.0     -1     -1.00   \n",
              "2            3.0     -1     -1.00   \n",
              "3            5.0     -1     -1.00   \n",
              "4            4.0    red      1.25   \n",
              "...          ...    ...       ...   \n",
              "123718       5.0     -1     -1.00   \n",
              "123719       4.0     -1     -1.00   \n",
              "123720       3.0     -1     -1.00   \n",
              "123721       3.0     -1     -1.00   \n",
              "123722       4.0    red      2.50   \n",
              "\n",
              "                                                  raicesl  rating technique  \\\n",
              "0       [i, be, on, the, ground, floor, of, a, dorm, b...     3.0        -1   \n",
              "1       [i, be, leave, a, job, after, a, shift, have, ...     2.0        -1   \n",
              "2       [twilight, my, present, home, i, be, leave, th...     3.0        -1   \n",
              "3       [when, your, favourite, song, be, announce, in...     2.0        -1   \n",
              "4       [serve, customer, be, in, a, mall, style, like...     2.0        -1   \n",
              "...                                                   ...     ...       ...   \n",
              "123718  [first, off, ali, do, not, have, the, father, ...    -1.0        -1   \n",
              "123719  [ali, ben, dan, and, i, be, all, in, the, clas...    -1.0        -1   \n",
              "123720  [i, be, in, some, sort, of, a, strange, arena,...    -1.0        -1   \n",
              "123721  [thois, be, suuuch, a, cool, dream, too, bad, ...    -1.0        -1   \n",
              "123722  [i, live, on, a, beach, in, a, very, lovely, h...    -1.0        -1   \n",
              "\n",
              "                                                      url             user  \\\n",
              "0       http://www.dreamjournal.net/journal/dream/drea...             haux   \n",
              "1       http://www.dreamjournal.net/journal/dream/drea...             haux   \n",
              "2       http://www.dreamjournal.net/journal/dream/drea...       PearlDiver   \n",
              "3       http://www.dreamjournal.net/journal/dream/drea...  LucidDreamer777   \n",
              "4       http://www.dreamjournal.net/journal/dream/drea...  LucidDreamer777   \n",
              "...                                                   ...              ...   \n",
              "123718  http://www.dreamjournal.net/journal/dream/drea...        MtDewWolf   \n",
              "123719  http://www.dreamjournal.net/journal/dream/drea...        MtDewWolf   \n",
              "123720  http://www.dreamjournal.net/journal/dream/drea...  Elemental_angel   \n",
              "123721  http://www.dreamjournal.net/journal/dream/drea...     MyBounciness   \n",
              "123722  http://www.dreamjournal.net/journal/dream/drea...          toric13   \n",
              "\n",
              "                                                    dream  \\\n",
              "0        i was on the ground floor of a dorm building ...   \n",
              "1        i was leaving a job after a shift had ended i...   \n",
              "2        twilight my present home i am leaving the hou...   \n",
              "3        when your favourite song is announced in your...   \n",
              "4        serving customers being in a mall styled like...   \n",
              "...                                                   ...   \n",
              "123718   first off ali did not have the father she doe...   \n",
              "123719   ali ben dan and i were all in the classroom a...   \n",
              "123720   i was in some sort of a strange arena facing ...   \n",
              "123721   thois is suuuch a cool dream too bad i dun re...   \n",
              "123722   i lived on a beach in a very lovely house exp...   \n",
              "\n",
              "                                      additional_comments  \\\n",
              "0                                                           \n",
              "1                                                           \n",
              "2       curious dream bl is one of the worst people i ...   \n",
              "3       p s the last song that i played before going t...   \n",
              "4                                                morning    \n",
              "...                                                   ...   \n",
              "123718   omg if this is precognitive i m killing someone    \n",
              "123719                                                      \n",
              "123720                  do not know where this came from    \n",
              "123721  well elavators symbloize rising up or down on ...   \n",
              "123722                                                      \n",
              "\n",
              "                                               themes  \\\n",
              "0                                           friendly    \n",
              "1                                   failure friendly    \n",
              "2       music action success failure health friendly    \n",
              "3                                          music fun    \n",
              "4                                          nightmare    \n",
              "...                                               ...   \n",
              "123718                                                  \n",
              "123719                                                  \n",
              "123720                                      violence    \n",
              "123721                            nightmare violence    \n",
              "123722                                                  \n",
              "\n",
              "                                                 settings  \\\n",
              "0                 town city indoors distorted unfamiliar    \n",
              "1                   indoors distorted familiar ambiguous    \n",
              "2       outdoors indoors distorted familiar unfamiliar...   \n",
              "3                                        school outdoors    \n",
              "4                                  mall outdoors indoors    \n",
              "...                                                   ...   \n",
              "123718                                            school    \n",
              "123719                                            school    \n",
              "123720                                                      \n",
              "123721                                                      \n",
              "123722                                              home    \n",
              "\n",
              "                                          characters  \\\n",
              "0                                  friend colleague    \n",
              "1                              colleague unfamiliar    \n",
              "2       other relative s friend stranger unfamiliar    \n",
              "3                                 colleague teacher    \n",
              "4                   child other relative s stranger    \n",
              "...                                              ...   \n",
              "123718                      other relative s friend    \n",
              "123719                                       friend    \n",
              "123720                               friend animals    \n",
              "123721                             other relative s    \n",
              "123722                                       friend    \n",
              "\n",
              "                                     emotions  \\\n",
              "0                                emotionless    \n",
              "1                                emotionless    \n",
              "2                     worry relaxed peaceful    \n",
              "3                 fear dread happiness shock    \n",
              "4       sadness worry fear dread emotionless    \n",
              "...                                       ...   \n",
              "123718            sadness fear dread anxiety    \n",
              "123719                             confusion    \n",
              "123720                             confusion    \n",
              "123721                              peaceful    \n",
              "123722                        worry peaceful    \n",
              "\n",
              "                                               activities  \\\n",
              "0               physical thinking visual location change    \n",
              "1               thinking visual movement location change    \n",
              "2       auditory physical thinking visual movement pro...   \n",
              "3       auditory thinking visual movement expressive c...   \n",
              "4       auditory physical thinking visual movement sea...   \n",
              "...                                                   ...   \n",
              "123718                                                      \n",
              "123719                                         searching    \n",
              "123720                                         searching    \n",
              "123721                                                      \n",
              "123722                                                      \n",
              "\n",
              "                                                   raices  \\\n",
              "0       [i, be, on, the, ground, floor, of, a, dorm, b...   \n",
              "1       [i, be, leave, a, job, after, a, shift, have, ...   \n",
              "2       [twilight, my, present, home, i, be, leave, th...   \n",
              "3       [when, your, favourite, song, be, announce, in...   \n",
              "4       [serve, customer, be, in, a, mall, style, like...   \n",
              "...                                                   ...   \n",
              "123718  [first, off, ali, do, not, have, the, father, ...   \n",
              "123719  [ali, ben, dan, and, i, be, all, in, the, clas...   \n",
              "123720  [i, be, in, some, sort, of, a, strange, arena,...   \n",
              "123721  [thois, be, suuuch, a, cool, dream, too, bad, ...   \n",
              "123722  [i, live, on, a, beach, in, a, very, lovely, h...   \n",
              "\n",
              "                                                     text  \\\n",
              "0        i was on the ground floor of a dorm building ...   \n",
              "1        i was leaving a job after a shift had ended i...   \n",
              "2        twilight my present home i am leaving the hou...   \n",
              "3        when your favourite song is announced in your...   \n",
              "4        serving customers being in a mall styled like...   \n",
              "...                                                   ...   \n",
              "123718   first off ali did not have the father she doe...   \n",
              "123719   ali ben dan and i were all in the classroom a...   \n",
              "123720   i was in some sort of a strange arena facing ...   \n",
              "123721   thois is suuuch a cool dream too bad i dun re...   \n",
              "123722   i lived on a beach in a very lovely house exp...   \n",
              "\n",
              "                                            raices_unidas  \n",
              "0       i be on the ground floor of a dorm building th...  \n",
              "1       i be leave a job after a shift have end it be ...  \n",
              "2       twilight my present home i be leave the house ...  \n",
              "3       when your favourite song be announce in your d...  \n",
              "4       serve customer be in a mall style like an anci...  \n",
              "...                                                   ...  \n",
              "123718  first off ali do not have the father she do no...  \n",
              "123719  ali ben dan and i be all in the classroom acro...  \n",
              "123720  i be in some sort of a strange arena face a bl...  \n",
              "123721  thois be suuuch a cool dream too bad i dun rem...  \n",
              "123722  i live on a beach in a very lovely house expen...  \n",
              "\n",
              "[123723 rows x 18 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVZ16bftQmwW"
      },
      "source": [
        "# 2. ¿Qué sueña la gente?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtcKmEbMRNMG"
      },
      "source": [
        "#Análisis de sentimientos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "amdUXFVfQ5Mc"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'nltk'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#no sé si usamos todo esto\u001b[39;00m\n\u001b[0;32m      4\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload([\n\u001b[0;32m      5\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstopwords\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m ])\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "#no sé si usamos todo esto\n",
        "nltk.download([\n",
        "     \"names\",\n",
        "     \"stopwords\",\n",
        "     \"state_union\",\n",
        "     \"twitter_samples\",\n",
        "     \"movie_reviews\",\n",
        "     \"averaged_perceptron_tagger\",\n",
        "     \"vader_lexicon\",\n",
        "     \"punkt\",\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS_RyKmcSMsj"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "df[\"sentiment\"] = df[\"text\"].apply(sia.polarity_scores)   #TARDA BASTANTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI2uH3JDhuAG"
      },
      "outputs": [],
      "source": [
        "df[\"sentiment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ww1RCcHzhxDY"
      },
      "outputs": [],
      "source": [
        "df[\"neg\"] = pd.Series\n",
        "df[\"pos\"] = pd.Series\n",
        "\n",
        "for i in df[\"sentiment\"].index:\n",
        "  df[\"neg\"][i] = df[\"sentiment\"][i][\"neg\"]\n",
        "  df[\"pos\"][i] = df[\"sentiment\"][i][\"pos\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VuiYa0DtonPY"
      },
      "outputs": [],
      "source": [
        "#Los que tienen más de 0,5 en positivo\n",
        "df[df[\"pos\"]>0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LbjaaIgFsL9p"
      },
      "outputs": [],
      "source": [
        "#Más de 0,7 en negativo\n",
        "df[df[\"neg\"]>0.7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "03PJKvy5r9mz"
      },
      "outputs": [],
      "source": [
        "#Histograma negativo\n",
        "df[\"neg\"].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4C05KbvEOOP"
      },
      "source": [
        "# Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m9U19bL7ELBB"
      },
      "outputs": [],
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "input = [row.split() for row in df['raices_unidas']] # separamos en una lista\n",
        "\n",
        "phrases = Phrases(input, min_count=30, progress_per=1000)\n",
        "\n",
        "bigram = Phraser(phrases)\n",
        "\n",
        "sentences = bigram[input] # obtenemos las palabras junto con bigramas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TfxgpxyFEWfn",
        "outputId": "fa75124a-f51e-458b-8d22-35213df17ad4"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-bac3b0c981a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m### ENTRENA EL MODELO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m### PRECOMPUTA DISTANCIAS (mas rapido)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "\n",
        "w2v_model = Word2Vec(min_count=20, # ignora palabras cuya frecuencia es menor a esta\n",
        "                     window=2, # tamanio de la ventana de contexto\n",
        "                     size=300, # dimension del embedding\n",
        "                     sample=6e-5, # umbral para downsamplear palabras muy frecuentes\n",
        "                     alpha=0.03, # tasa de aprendizaje inicial (entrenamiento de la red neuronal)\n",
        "                     min_alpha=0.0007, # tasa de aprendizaje minima\n",
        "                     negative=20, # penalidad de palabras muy frecuentes o poco informaitvas\n",
        "                     workers=cores) # numero de cores para entrenar el modelo\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=10000) # construye el vocabulario\n",
        "\n",
        "### ENTRENA EL MODELO\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "### PRECOMPUTA DISTANCIAS (mas rapido)\n",
        "w2v_model.init_sims(replace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5oubl29FIW3"
      },
      "outputs": [],
      "source": [
        "w2v_model.wv.most_similar(positive=[\"sex\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHSE17nt1tv8"
      },
      "source": [
        "# Tópicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2ozjzgX1r8X"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías habituales\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rY8U24471xvK"
      },
      "outputs": [],
      "source": [
        "# Objetos de sklearn para hacer tópicos\n",
        "from sklearn.feature_extraction.text import CountVectorizer # Contador de frecuencia\n",
        "from sklearn.feature_extraction.text import TfidfTransformer # Creador de tf-idf\n",
        "\n",
        "# Algoritmos de descomposición de tópicos\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8lauNvq10bC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Creamos el objeto contador de palabras, pidiéndole que remueve\n",
        "# las stopwords, los términos que aparecen en un único documento (min_df)\n",
        "# y los términos que aparecen en más del 70% de los documentos (max_df).\n",
        "# Esto es para eliminar palabras raras (o errores de tipeo) y\n",
        "# términos que seguramente son stopwords no incluídos en la lista\n",
        "count = CountVectorizer(min_df = 2, max_df = 0.70, stop_words = stopwords)\n",
        "\n",
        "# Ajustamos con los datos. Acá especificamente creamos una matriz documentos-términos\n",
        "x_count = count.fit_transform(df['raices_unidas'])\n",
        "\n",
        "# Dimensions de la matriz doc-tér\n",
        "print(x_count.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMx8OmJE12AG"
      },
      "outputs": [],
      "source": [
        "# Creamos el objeto tf-idf. Le decimos además que devuelva los\n",
        "# vectores documento con norma euclídea igual a 1 (norm = 'l2')\n",
        "tfidf = TfidfTransformer(norm = 'l2')\n",
        "\n",
        "# Creamos la matriz tf-idf a partir de la matriz de frecuencias\n",
        "x_tfidf = tfidf.fit_transform(x_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wtm6HqrD13lI"
      },
      "outputs": [],
      "source": [
        "# Elijamos la cantidad de tópicos\n",
        "n_components = 5\n",
        "\n",
        "# Construímos el objeto NMF con los tópicos indicados\n",
        "nmf = NMF(n_components = n_components)\n",
        "\n",
        "# Aplicamos sobre nuestros datos\n",
        "x_nmf = nmf.fit_transform(x_tfidf)\n",
        "\n",
        "# Dimensión de la matriz transformada\n",
        "print(x_nmf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiosTeSe15Js"
      },
      "outputs": [],
      "source": [
        "# Objeto índice: término de nuestro vocabulario\n",
        "vocabulary = {item: key for key, item in count.vocabulary_.items()}\n",
        "\n",
        "# Para cada componente\n",
        "for n in range(n_components):\n",
        "\n",
        "  # Ordenamos una lista del largo de nuestro vocabulario según el peso en cada componente y nos quedamos con los primeros 10\n",
        "  list_sorted = sorted(range(nmf.components_.shape[1]), reverse = True, key = lambda x: nmf.components_[n][x])[:10]\n",
        "\n",
        "  # Printeamos los términos asociados a los valores más grande de cada una de las componentes\n",
        "  print(', '.join([vocabulary[i] for i in list_sorted]))\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mAf0IT52_2z"
      },
      "outputs": [],
      "source": [
        "# WordClouds\n",
        "wc_atributos = {'height' : 800,\n",
        "                'width' : 1200,\n",
        "                'background_color' : 'white',\n",
        "                'max_words' : 20\n",
        "                } # Defino los parámetros que les voy a pasar a los wordclouds\n",
        "\n",
        "# Creo la figura\n",
        "fig, axs = plt.subplots(n_components, figsize = (6,20))\n",
        "\n",
        "# Recorro para todas las componentes\n",
        "for n in range(n_components):\n",
        "\n",
        "  # 10 términos más pesados\n",
        "  list_sorted = sorted(range(len(vocabulary)), reverse = True, key = lambda x: nmf.components_[n][x])[:10]\n",
        "\n",
        "  # Diccionario término: peso\n",
        "  comp_dict = {vocabulary[i]: nmf.components_[n][i] for i in list_sorted}\n",
        "\n",
        "  # Creo el wordlcoud\n",
        "  wc = WordCloud(**wc_atributos # De esta forma, le estoy diciendo a la función que expanda el diccionario de atributos de forma tal de que entienda lo que quiero que haga\n",
        "                 ).generate_from_frequencies(comp_dict)\n",
        "\n",
        "  axs[n].set_title('Tópico {}'.format(n))\n",
        "  axs[n].imshow(wc)\n",
        "  axs[n].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP_cQ86e66_L"
      },
      "outputs": [],
      "source": [
        "# Normalizador\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "# Creamos un objeto para normalizar a que la suma dé 1\n",
        "norm = Normalizer('l1')\n",
        "\n",
        "# Sobreescribimos sobre la matriz de documentos-tópicos\n",
        "x_nmf = norm.fit_transform(x_nmf)\n",
        "\n",
        "# Guardemos en el dataframe esta información\n",
        "for n in range(n_components):\n",
        "  df['nmf_comp{}'.format(n)] = x_nmf[:,n]\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPbKrfPS69D6"
      },
      "outputs": [],
      "source": [
        "df_metodo = df.groupby('technique').mean()\n",
        "\n",
        "# Inspeccionemoslo\n",
        "df_metodo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQhYfa_I6_e0"
      },
      "outputs": [],
      "source": [
        "# El eje x es la década\n",
        "x = df_metodo.index\n",
        "\n",
        "# El eje y son las distribuciones\n",
        "y = df_metodo[['nmf_comp{}'.format(i) for i in range(n_components)]].to_numpy()\n",
        "\n",
        "plt.figure(figsize = (8,5))\n",
        "plt.stackplot(x, y.T) # Stackplot: sirve para graficar distribuciones\n",
        "#plt.xlim([0, 90])\n",
        "plt.ylim([0, 1.00])\n",
        "plt.yticks([])\n",
        "plt.xlabel('Método')\n",
        "plt.legend(['Tópico {}'.format(i) for i in range(n_components)], loc = (1.05, 0.60))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiFXIVocRQ_3"
      },
      "source": [
        "# 3. ¿Cómo sueña?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kV1WjPQF_3I"
      },
      "outputs": [],
      "source": [
        "#Nos quedamos solo con los que contestaron green o red\n",
        "index_red = df[\"intent\"]==\"red\"\n",
        "index_green = df[\"intent\"]==\"green\"\n",
        "\n",
        "index_or = index_green + index_red\n",
        "df = df[index_or]\n",
        "\n",
        "#Tabla de contingencia de lucidity e intent\n",
        "pd.crosstab(df[\"intent\"], df[\"lucidity\"], margins=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czbpNg1h6cwK"
      },
      "outputs": [],
      "source": [
        "#Qué técnicas usaron\n",
        "df[\"technique\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1zhuRXuEqy0"
      },
      "outputs": [],
      "source": [
        "#Tabla de contingencia de técnica e intent\n",
        "pd.crosstab(df[\"intent\"], df[\"technique\"], margins = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7s2I_OnEsWx"
      },
      "outputs": [],
      "source": [
        "#Tabla de contingencia de lucidity y técnica\n",
        "pd.crosstab(df[\"lucidity\"], df[\"technique\"], margins = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sJ37GPrtLGl"
      },
      "source": [
        "#Nubes de palabras por intention: green/red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCzldZNY8sQB"
      },
      "outputs": [],
      "source": [
        "#Me quedo con las raíces\n",
        "raices = df[\"raices_unidas\"].transpose()\n",
        "raices_green = df[\"raices_unidas\"][df[\"intent\"]==\"green\"].transpose()\n",
        "raices_red = df[\"raices_unidas\"][df[\"intent\"]==\"red\"].transpose()\n",
        "\n",
        "#Las junto todos en un solo texto de raices\n",
        "todos_textos_green = \" \".join(raices_green)\n",
        "todos_textos_red = \" \".join(raices_red)\n",
        "\n",
        "#Las cuento\n",
        "print(\"Hay en total:\", raices.size, \"relatos\")  #hay vacíos?\n",
        "print(\"De los cuales son red:\", raices_red.size)\n",
        "print(\"La cant de green son:\", raices_green.size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jSMhiPwb0Uj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cargamos del paquete nltk las stopwords a la lista \"stopwords\"\n",
        "import nltk\n",
        "nltk.download('stopwords') # hay que descargar este modulo en particular\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "print(stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez-PO0hZjEE8"
      },
      "outputs": [],
      "source": [
        "#Limpieza adicional para este set\n",
        "stopwords = stopwords + [\"quot\", \"nbsp\", \"additional\", \"comment\", \"rsquo\", \"rdquo\", \"unfamiliar character\"] #add emotions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI4v_Jh3BoE2"
      },
      "outputs": [],
      "source": [
        "print(df[\"raices\"][151])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfXz1KRD8v6N"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud # importo la funcion WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creo el objeto WordCloud sacando la lista de stopwords\n",
        "wc = WordCloud(stopwords=stopwords, background_color=\"white\", colormap=\"Dark2\",\n",
        "               max_font_size=150, random_state=42)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [16,12] # tamaño de los plots\n",
        "\n",
        "#Genero green\n",
        "wc.generate(todos_textos_green)\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Green sin stopwords\")\n",
        "plt.show()\n",
        "\n",
        "#Genero red\n",
        "wc.generate(todos_textos_red)\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Red sin stopwords\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KTtwrenzMhQ"
      },
      "outputs": [],
      "source": [
        "# Ahora con stopwords\n",
        "wc = WordCloud(background_color=\"white\", colormap=\"Dark2\",\n",
        "               max_font_size=150, random_state=42)\n",
        "\n",
        "wc.generate(todos_textos_green)  # acá le pido que genere los WC a partir del texto de cada año\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Green con stopwords\")\n",
        "plt.show()\n",
        "\n",
        "wc.generate(todos_textos_red)  # acá le pido que genere los WC a partir del texto de cada año\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Red con stopwords\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJDPE6GMoeiA"
      },
      "outputs": [],
      "source": [
        "#Armo listas de raices green/red con y sin stopwords:\n",
        "#Primero con stopwords:\n",
        "lista_raices_green = df[\"raices\"][df[\"intent\"]==\"green\"].transpose()\n",
        "lista_raices_red = df[\"raices\"][df[\"intent\"]==\"red\"].transpose()\n",
        "\n",
        "#Función que remueve de una lista de strings los elementos en stopwords\n",
        "def sw_remover3(lista):\n",
        "   return [value for value in lista if not value in stopwords]\n",
        "\n",
        "#Aplico la función y lo guardo en una nueva columna\n",
        "lista_raices_green_sinsw = lista_raices_green.apply(sw_remover3)\n",
        "lista_raices_red_sinsw = lista_raices_red.apply(sw_remover3)\n",
        "\n",
        "# Se borraron los stopwords, por ejemplo:\n",
        "print(lista_raices_red[4])\n",
        "print(lista_raices_red_sinsw[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL8YOGcCxJZm"
      },
      "source": [
        "Sobre el dataset:  \n",
        "-1 significa que no había datos al scrapear  \n",
        "No hay Nan entre los elementos.  \n",
        "Hay ruido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTzj_zfKzZw-"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías habituales\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsntAzeVzhd4"
      },
      "outputs": [],
      "source": [
        "# Objetos de sklearn para hacer tópicos\n",
        "from sklearn.feature_extraction.text import CountVectorizer # Contador de frecuencia\n",
        "from sklearn.feature_extraction.text import TfidfTransformer # Creador de tf-idf\n",
        "\n",
        "# Algoritmos de descomposición de tópicos\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4xPEhPffkv8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftEs0t_NfonF"
      },
      "source": [
        "#RANKEO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRoRsAs-fr4_"
      },
      "outputs": [],
      "source": [
        "\n",
        "ratings = dfRank[\"rating\"].value_counts().to_dict()\n",
        "\n",
        "print(\"Total de sueños no rankeados = \" + str(ratings[-1]))\n",
        "print(\"Total de sueños rankeados = \" + str(ratings[5]+ratings[4]+ratings[3]+ratings[2]+ratings[1]))\n",
        "print(\"Total de sueños rankeados positivos = \" + str(ratings[5]+ratings[4]))\n",
        "print(\"Total de sueños rankeados negativos = \" + str(ratings[2]+ratings[1]))\n",
        "print(\"Total de sueños rankeados neutros = \"+str(ratings[3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20ogg03eZQk6"
      },
      "source": [
        "Creo los dataframes segun rankeo positivo o negativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC6XZQSiWQ_Y"
      },
      "outputs": [],
      "source": [
        "dfRank = dfRank.loc[dfRank[\"rating\"]>0] #elimino los suenios no rankeados == -1\n",
        "dfPosRank = dfRank.loc[dfRank[\"rating\"]>3] #asumo rank pos == mayor a 3\n",
        "dfNegRank = dfRank.loc[dfRank[\"rating\"]<3] #asumo rank neg == menor a 3\n",
        "\n",
        "rank = dfRank[\"user\"].value_counts().to_dict()\n",
        "rankPos = dfPosRank[\"user\"].value_counts().to_dict()\n",
        "rankNeg = dfNegRank[\"user\"].value_counts().to_dict()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzHOfQ9sQIY-"
      },
      "source": [
        "##Son los suenios rankeados altos de los mismos usuarios?\n",
        "SI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ9v_XtAQGeN"
      },
      "outputs": [],
      "source": [
        "data = list(rankPos.values())\n",
        "\n",
        "plt.pie(data, labels= rankPos.keys())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgHoc0zyWihk"
      },
      "source": [
        "## quiero ver cuantos usuarios escribieron que porcentaje del total\n",
        " es decir, se que aproximadamente 30 usuarios escribieron el 50% del total de los rankeados positivos, 200 usuarios el 5% y 8000 usuarios el otro 45%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4cdPaVUWu4T"
      },
      "outputs": [],
      "source": [
        "cantUsuarios = np.zeros(5)\n",
        "cantPublicaciones = np.zeros(5)\n",
        "etiquetas = [\"1-10\",\"11-30\",\"31-50\",\"51-100\",\"101-453\"]\n",
        "\n",
        "\n",
        "keys = list(rankPos.keys())\n",
        "analizar5porciento = []\n",
        "analizar95porciento = []\n",
        "\n",
        "\n",
        "for i in range(len(rankPos.keys())):\n",
        "  key = keys[i]\n",
        "  if(rankPos[key] < 11):\n",
        "    cantPublicaciones[0] += rankPos[key]\n",
        "    cantUsuarios[0] += 1\n",
        "    #para analisis del otro parte\n",
        "    analizar95porciento.append(key)\n",
        "  elif(rankPos[key] < 31):\n",
        "    cantPublicaciones[1] += rankPos[key]\n",
        "    cantUsuarios[1] += 1\n",
        "    #para mi grafico d analisis ams adelante\n",
        "    analizar5porciento.append(key)\n",
        "  elif(rankPos[key] < 51):\n",
        "    cantPublicaciones[2] += rankPos[key]\n",
        "    cantUsuarios[2] += 1\n",
        "    #para mi grafico d analisis ams adelante\n",
        "    analizar5porciento.append(key)\n",
        "  elif(rankPos[key] < 101):\n",
        "    cantPublicaciones[3] += rankPos[key]\n",
        "    cantUsuarios[3] += 1\n",
        "    #para mi grafico d analisis ams adelante\n",
        "    analizar5porciento.append(key)\n",
        "  else:\n",
        "    cantPublicaciones[4] += rankPos[key]\n",
        "    cantUsuarios[4] += 1\n",
        "    #para mi grafico d analisis ams adelante\n",
        "    analizar5porciento.append(key)\n",
        "\n",
        "\n",
        "for i in range(len(cantUsuarios)):\n",
        "  cantUsuarios[i] = str(cantUsuarios[i])\n",
        "\n",
        "\n",
        "print(cantPublicaciones,cantUsuarios)\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(nrows = 1, ncols = 2)\n",
        "axs[0].set_title(\"Suenios\")\n",
        "axs[0].pie(cantPublicaciones, labels = cantUsuarios ,colors = plt.get_cmap('Set3').colors, autopct='%1.2f%%')\n",
        "#axs[1].set_title[\"Usuarios\"]\n",
        "axs[1].pie(cantUsuarios, labels = etiquetas ,colors = plt.get_cmap('Set3').colors, autopct='%1.2f%%')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKns7kaXpGbp"
      },
      "source": [
        "grafico 1: porcentaje de entradas y usuarios que las escribieron/// suma de publicaciones que hicieron los usuarios entre rango\n",
        "\n",
        "grafico 2: usuarios sobre entradas que publicaron\n",
        "esto me lleva a querer analizar a este 5% de los usuarios///cantidad de  usuarios con x entradas entre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX-vLt9xB3Og"
      },
      "outputs": [],
      "source": [
        "plt.bar(height = cantPublicaciones, x= etiquetas)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5H1oFdImIkV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.hist(rankPos.values(), bins = 453,color = \"darkcyan\")\n",
        "plt.xticks(np.arange(0,453,step=20))\n",
        "plt.ylabel(\"Usuarios\")\n",
        "plt.xlabel(\"Cantidad de entradas publicadas\")\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiyabHZXqAZf"
      },
      "outputs": [],
      "source": [
        "lista_de_entradas = [x for x in rankPos.values() if x < 50]\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.hist(lista_de_entradas, bins = 50,color = \"darkcyan\")\n",
        "plt.xticks(np.arange(0,50,step=1))\n",
        "plt.ylabel(\"Usuarios\")\n",
        "plt.xlabel(\"Cantidad de entradas publicadas\")\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iR9uUastrBF"
      },
      "outputs": [],
      "source": [
        "lista_de_entradas3 = [x for x in rankNeg.values() if x < 453]\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.hist(lista_de_entradas3, bins = 453,color = \"m\")\n",
        "plt.xticks(np.arange(0,453,step=20))\n",
        "plt.ylabel(\"Usuarios\")\n",
        "plt.xlabel(\"Cantidad de entradas publicadas\")\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ2gEO5mvEEp"
      },
      "outputs": [],
      "source": [
        "lista_de_entradas2 = [x for x in rankNeg.values() if x < 50]\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.hist(lista_de_entradas2, bins = 50,color = \"m\")\n",
        "plt.xticks(np.arange(0,50,step=1))\n",
        "plt.ylabel(\"Usuarios\")\n",
        "plt.xlabel(\"Cantidad de entradas publicadas\")\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mTTSR5KCryn"
      },
      "source": [
        "##quiero analizar al 5% de los usuarios que publicaron mas del 50% de los posRank\n",
        "\n",
        "voy a hacer un promedio de todas sus publicaciones y ver si tienen mas publicaciones positivas que negativas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4HZ1K3xCrme"
      },
      "outputs": [],
      "source": [
        "\n",
        "promediar = np.zeros(2)\n",
        "for n in range(len(analizar5porciento)):\n",
        "  i = analizar5porciento[n]\n",
        "  if(i in rankPos):\n",
        "    promediar[0] += rankPos[i]\n",
        "  if(i in rankNeg):\n",
        "    promediar[1] += rankNeg[i]\n",
        "\n",
        "data = promediar / len(analizar5porciento)\n",
        "\n",
        "promediar1 = np.zeros(2)\n",
        "for n in range(len(analizar95porciento)):\n",
        "  i = analizar95porciento[n]\n",
        "  if(i in rankPos):\n",
        "    promediar1[0] += rankPos[i]\n",
        "  if(i in rankNeg):\n",
        "    promediar1[1] += rankNeg[i]\n",
        "\n",
        "data1 = promediar1 / len(analizar95porciento)\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(4,8))\n",
        "plt.bar(height=promediar , x=[\"Positivo\",\"Negativo\"], color = [\"blue\",\"red\"], width=0.8)\n",
        "\n",
        "plt.show()\n",
        "print(promediar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snbCfZ6RNjjz"
      },
      "outputs": [],
      "source": [
        "promediar1 = np.zeros(2)\n",
        "for n in range(len(analizar95porciento)):\n",
        "  i = analizar95porciento[n]\n",
        "  if(i in rankPos):\n",
        "    promediar1[0] += rankPos[i]\n",
        "  if(i in rankNeg):\n",
        "    promediar1[1] += rankNeg[i]\n",
        "\n",
        "data1 = promediar1 / len(analizar95porciento)\n",
        "\n",
        "plt.figure(figsize=(4,8))\n",
        "plt.bar(height=promediar1 , x=[\"Positivo\",\"Negativo\"], color = [\"blue\",\"red\"])\n",
        "plt.show()\n",
        "print(promediar1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL6GoZVaIrRK"
      },
      "source": [
        "yo de aca concluyo que tienen muchos buenos rankeados pero porque escriben muchos-> esto me lleva a descartar una hipotesis de mentiras/hacerlo para obtener puntaje alto\n",
        "\n",
        "\n",
        "\n",
        "vemos que las sumas de los suenios negativos y los positivos nos dice que el 5% que tienen muchos bien rankeados es porque escriben mucho. mientras que el 95% esta mas parejo en cuanto al rank?? nose si meter esto /// creo q no"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q85oPt_xZa8S"
      },
      "source": [
        "['cohesion', 'intent', 'lucidity', 'raicesl', 'rating', 'technique', 'url', 'user', 'dream', 'additional_comments', 'themes', 'settings', 'characters', 'emotions', 'activities']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Quiero hacer porcentajes por cada usuario q publico alguna vez algun suenio para ver como suelen ser rankeados sus suenios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSCh1sGwZbHv"
      },
      "outputs": [],
      "source": [
        "\n",
        "dicPorcentajes = dict()\n",
        "rankIT = list(rank.keys())\n",
        "for i in range(len(rank.keys())):\n",
        "  key = rankIT[i]\n",
        "  if(key in rankPos):\n",
        "    pos = (rankPos[key]*100)/rank[key]\n",
        "    pos = round(pos,1)\n",
        "  else:\n",
        "    pos = 0\n",
        "  if(key in rankNeg):\n",
        "    neg = (rankNeg[key]*100)/rank[key]\n",
        "    neg = round(neg,1)\n",
        "  else:\n",
        "    neg = 0\n",
        "  neu = 100 -(pos+neg)\n",
        "  dicPorcentajes[key] = [pos,neg,neu]\n",
        "\n",
        "\n",
        "#busqueda\n",
        "busquedaPositivos = []\n",
        "it = list(dicPorcentajes.keys())\n",
        "for i in range(len(dicPorcentajes.keys())):\n",
        "  key = it[i]\n",
        "  #if(dicPorcentajes[key][0]>dicPorcentajes[key][1] and rank[key]>8):\n",
        "  if(dicPorcentajes[key][0]>dicPorcentajes[key][1] and rank[key]>8):\n",
        "    busquedaPositivos.append([key,dicPorcentajes[key][0],dicPorcentajes[key][1],rank[key]])\n",
        "\n",
        "#busquedaPositivos#[user,%pos,%neg,cantPublicaciones]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA8ZIX6LhQW7"
      },
      "source": [
        "de hecho existen usuarios con todos sus suenios rankeados positivos pero estos no superan los 10 suenios publicados"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "O32QYyzuxsa3",
        "CkGdGHdsyQwu",
        "KtcKmEbMRNMG",
        "i4C05KbvEOOP",
        "tHSE17nt1tv8",
        "MiFXIVocRQ_3"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
